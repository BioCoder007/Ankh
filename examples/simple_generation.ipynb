{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aedf1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import torch\n",
    "import random\n",
    "\n",
    "seed = 7\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "import ankh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21265256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74747f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_mask_tokens(n):\n",
    "    return [f\"<extra_id_{i}>\" for i in range(n)]\n",
    "\n",
    "def append_n_mask_tokens(input_, n):\n",
    "    return input_ + \"\".join(get_n_mask_tokens(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7424699b",
   "metadata": {},
   "source": [
    "### Select the available device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b6dad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Available device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a78051",
   "metadata": {},
   "source": [
    "### Load Ankh large model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d32b5d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(144, 1536)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(144, 1536)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "              (relative_attention_bias): Embedding(64, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (24): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (25): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (26): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (27): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (28): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (29): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (30): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (31): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (32): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (33): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (34): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (35): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (36): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (37): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (38): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (39): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (40): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (41): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (42): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (43): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (44): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (45): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (46): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (47): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(144, 1536)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "              (relative_attention_bias): Embedding(64, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "              (wo): Linear(in_features=3840, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=144, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tokenizer = ankh.load_large_model(generation=True)\n",
    "model.eval()\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e34f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1878705152\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of parameters:\", get_num_params(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc76898",
   "metadata": {},
   "source": [
    "### Test Autoregressive generation on a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725d8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = \"QVQLVESGGGLVQPGGSL\"\n",
    "num_new_tokens = 5\n",
    "masked_seq = append_n_mask_tokens(test_seq, n=num_new_tokens)\n",
    "maximum_length = num_new_tokens * 2  + 1\n",
    "num_beams = 5\n",
    "temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa17126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode_plus(masked_seq, add_special_tokens=True, return_tensors='pt') \n",
    "input_ids = encoded['input_ids'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f57cb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 16,   6,  16,   4,   6,   9,   7,   5,   5,   5,   4,   6,  16,  13,\n",
       "           5,   5,   7,   4, 143, 142, 141, 140, 139,   1]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f1c3563",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = model.generate(input_ids=input_ids, temperature = temperature,\n",
    "                                max_length = maximum_length,\n",
    "                                num_beams = num_beams,\n",
    "                                do_sample=True if temperature > 0 else False)\n",
    "\n",
    "output_ids = generation[0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "477d3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_tokens = list(tokenizer.decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4b215e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QVQLVESGGGLVQPGGSLVQPGG\n"
     ]
    }
   ],
   "source": [
    "test_output = f\"{test_seq}\" + \"\".join(generated_tokens)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e8d60f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
